\documentclass[sigconf]{acmart}

\usepackage{hyperref}

\usepackage{endfloat}
\renewcommand{\efloatseparator}{\mbox{}} % no new page between figures

\usepackage{booktabs} % For formal tables

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\begin{document}
\title{Big data analysis in Finance Sector}


\author{Dhanya Mathew}
\orcid{HID328}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{711 N Park Ave}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{dhmathew@iu.edu}

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
In order to understand what drives customer profit, we want to be able to predict what profit group (extremely unprofitable, average, extremely profitable etc.) a set of customers falls into based on their data at any given time.
\end{abstract}

\keywords{ACM proceedings, \LaTeX, text tagging}


\maketitle

\section{Introduction}

Big data as it's name implies, refers to large and complex data which continues to grow enormously day by day. There are huge number of sectors or applications including government, business, technology, universities, health-care, finance, manufacturing etc who make use of big data by obtaining meaningful information using big data technologies. This paper investigates how big data is helpful in financial firms in terms of predictive analysis and profitable growth. The finance sector is generating huge amounts of data on a daily basis from products and marketing, banking, business, to share market. Finance is a very sensitive field and any useful insight can make a positive impact on the overall turnover. Historic data analysis and real time data analysis are equally important in terms of finance sector. The key idea behind is how to retrieve the "signal" of relevant information form the bulk of data. Let us explore the wide range of possibilities of big data analysis that finance sector can come up with including decision making, discovery of new business opportunities, enhanced productivity and efficiency, risk management, fraud detection, innovation possibilities, efficiency and growth and a detailed view of customer segmentation in banking sector. 

\subsection{Efficient decision making}

The era of big data helps financial firms to take quality business decisions related to expanding revenues, managing costs, hiring resources etc based on effective data analysis which provide access to real-time insights.  Data-driven decision making is one of the key advantages of big data technologies. Data driven decision making approach includes data storage, data elaboration, data analysis and decision making. 

\textit{Data storage:} Even though big data does not defines by the size alone, we need the right means to store the huge volume and variety of data. Big data is distributed - stored across many machines and managed with Hadoop File System and distributed DBs like HBase and Apache Cassandra.

\textit{Data elaboration:} Generate combined information by eliminating unwanted data using data cleansing methods like grouping, joining, filtering etc(Spark, R, MapReduce, Storm). 

\textit{Data Analysis:} Big data analysis is the process of analyzing the data to derive the semantics of the available data to understand the hidden patterns, correlations, market trends, customer preferences which helps the organizations to take more informed decisions. Visualization tools include- Tableau,Google chart, D3, Fusion chart etc.

\textit{Decision making:} Data-driven decision making based on the analysis.

\subsection{Increased productivity and growth}
Compared to traditional data warehouses, the big data concept of Data lakes to store raw data offers more flexibility in data access and analysis. Large volumes of data are stored, managed and analyzed in data lakes  by using automated and sophisticated analytical tools. 

Data Lakes can be accessed by Machine learning algorithms, In-memory technologies, fast access DBs, big data queries and real-time analysis methods which consume less time to come up with meaningful information and reports.

\textit{Data lakes:} Data Lakes can be compared to the actual lakes where water doesn't get filled like that instead there are rivers or streams that bring water to it. In data lakes this is called ingestion of data. we collect all the data that we required to analyze to reach our goal irrespective of the source. These ‘streams’ of data come in several formats: structured data (simply said, data from a traditional relational database or even spreadsheet: rows and columns), unstructured data (social, video, email, text,…), data from all sorts of logs (e.g weblogs, clickstream analysis,…), XML, machine-to-machine, IoT and sensor data,, you name it (logs and XML are also called semi-structured data). There can be data filters in place based on the requirements.



\subsection{Identify business priorities}

\subsection{Risk Management}

\subsection{Understand new business opportunities}

\subsection{Discovery of innovation possibilities}

\subsection{Fraud detection}

\subsection{Cost effective information gathering}

\subsection{Customer Segmentation and personalized marketing}



\begin{acks}

  The authors would like to thank Dr. Yuhua Li for providing the
  matlab code of the \textit{BEPS} method.

  The authors would also like to thank the anonymous referees for
  their valuable comments and helpful suggestions. The work is
  supported by the \grantsponsor{GS501100001809}{National Natural
    Science Foundation of
    China}{http://dx.doi.org/10.13039/501100001809} under Grant
  No.:~\grantnum{GS501100001809}{61273304}
  and~\grantnum[http://www.nnsf.cn/youngscientsts]{GS501100001809}{Young
    Scientsts' Support Program}.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\end{document}
